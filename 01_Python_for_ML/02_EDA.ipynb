{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "317c3d62-095e-4d00-aed9-675f91608ad3",
      "metadata": {
        "editable": true,
        "id": "317c3d62-095e-4d00-aed9-675f91608ad3",
        "tags": []
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "## DS-3001: Machine Learning 1\n",
        "\n",
        "Content adapted from Terence Johnson (UVA)\n",
        "\n",
        "**Notebook Summary**: In this notebook, we will discuss the process of Exploratory Data Analysis (EDA). We will talk through how to quickly explore the features in your data via statistical descriptions and quick visualizations. We will prioritize quick visualizations rather than publication ready figures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0ded6e-f3c0-48e4-911b-b4980a64b730",
      "metadata": {
        "id": "7f0ded6e-f3c0-48e4-911b-b4980a64b730"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "- **Exploratory Data Analysis (EDA):** A process performed on cleaned data to understand some basic summaries and visualizations. Helps us understand the basic properties of the data and whether they are clean enough to proceed.\n",
        "\n",
        "- **Analyzing one or two variables at a time:** We are interested in understanding the distribution of a single variable or the relationship between two variables.\n",
        "\n",
        "- **No unique way to do EDA:** This can be an exhausting process, and there is no uniquely correct way to do it: choices have consequences.\n",
        "\n",
        "- **Focus on useful graphs rather than pretty graphs for now:** Since we are doing EDA and not Visualization, the emphasis is on *useful* graphs, not necessarily *pretty* ones\n",
        "\n",
        "- **Working with Pandas for now:** We will stay inside Pandas, and introduce PyPlot and Seaborn in the next lecture.\n",
        "\n",
        "- **Using pre-trial data for visualization:** Last time, we cleaned the pretrial data, which works well for visualizations: There are many interesting numeric variables, categorical variables, and dummy variables. We'll use it again today."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting up the Environment\n",
        "\n",
        "* First, we'll load in the necessary packages.\n",
        "* Second, we'll mount our Google Drive to the notebook so that we can access the files for this class.\n",
        "* Third, we'll change the working directory to the folder for this class.\n",
        "* Fourth, we'll load in the pre-trial data from the Data Wrangling notebook."
      ],
      "metadata": {
        "id": "VpVIfRAtfhQY"
      },
      "id": "VpVIfRAtfhQY"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # Pandas automatically uses some pyplot functions, so we need it loaded\n",
        "import os # For changing directory"
      ],
      "metadata": {
        "id": "_JIYysM1e5LF"
      },
      "id": "_JIYysM1e5LF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GrbzBTKufJ9t"
      },
      "id": "GrbzBTKufJ9t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path_to_DS_3001_folder = '/content/drive/MyDrive/DS-3001/01_Python_for_ML'\n",
        "\n",
        "# Update the path to your folder for the class\n",
        "# Where you stored the data from the previous noteboook\n",
        "path_to_DS_3001_folder = ''\n",
        "os.chdir(path_to_DS_3001_folder)"
      ],
      "metadata": {
        "id": "KYCwsxOBe9lJ"
      },
      "id": "KYCwsxOBe9lJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfa5421-2bfb-459e-9550-c60674665328",
      "metadata": {
        "id": "fcfa5421-2bfb-459e-9550-c60674665328"
      },
      "outputs": [],
      "source": [
        "# Read in the cleaned version of the pretrial data\n",
        "# Point to where you stored the file\n",
        "trial_df = pd.read_csv('./data/pretrial_data.csv', low_memory=False)\n",
        "print(trial_df.head(),'\\n')\n",
        "print(trial_df.describe(),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note:* If mounting your drive does not work, you can find the cleaned version of the data set on Canvas. Upload it to the file system in Google Colab by hitting the folder icon to the left and then the upload button. You can upload the file and then load it in as a data frame from there."
      ],
      "metadata": {
        "id": "Djw9-O2nohu5"
      },
      "id": "Djw9-O2nohu5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring a Single Variable\n",
        "\n",
        "We will start with methods for exploring the distribution of or characterizing a single variable. As we mentioned in the previous lecture (01_Data_Wrangling), variables can either be numeric or categorical. We will start by describing a single numeric value."
      ],
      "metadata": {
        "id": "__GJGY9EjASB"
      },
      "id": "__GJGY9EjASB"
    },
    {
      "cell_type": "markdown",
      "id": "27a19c99-1dd9-4823-84a5-7923e88f6357",
      "metadata": {
        "id": "27a19c99-1dd9-4823-84a5-7923e88f6357"
      },
      "source": [
        "### Histograms (Single Variable, Numeric)\n",
        "\n",
        "- **Histogram:** A fundamental and powerful tool for visualizing numeric data of a single variable. We got an introduction to histograms in 01_Data_Wrangling, but here we will go more in-depth on how they work:\n",
        "  \n",
        "- **How Histograms Are Created:**\n",
        "  - Take the minimum and maximum values that the variable takes, and divide the range into $B$ equally spaced *bins*. For example, if the min value is 0 and the max value is 100 and $B=4$, the bins are $\\{ [0,25), [25,50), [50,75), [75,100] \\}$.\n",
        "  - For each bin, count the number of observations that fall into that bin.\n",
        "  - Plot the result as a bar graph, where the count in the bin equals the height of the bar.\n",
        "\n",
        "- At this stage, picking the number of `bins=B` is a matter of \"taste.\" Note, the number of bins will shape how the graph looks and thus can change your interpretation, so choose and interpret carefully.\n",
        "\n",
        "- You can quickly create a histogram directly from a Pandas dataframe using the following notation: `df[var].plot.hist(bins=B)`. If you don't include a value for $B$, Pandas will use a default value of 10."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quickly clean the GiniIndex variable using what we learned from the Wrangling Data Set"
      ],
      "metadata": {
        "id": "kPnn5TXdhUAV"
      },
      "id": "kPnn5TXdhUAV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca88869-f15a-4606-8cf1-846c6b522959",
      "metadata": {
        "id": "1ca88869-f15a-4606-8cf1-846c6b522959"
      },
      "outputs": [],
      "source": [
        "# Create a histogram of the gini variable with 20 bins\n",
        "# Set grid to false"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb9c266c-6d43-40a4-94da-24bcea5b6633",
      "metadata": {
        "id": "bb9c266c-6d43-40a4-94da-24bcea5b6633"
      },
      "source": [
        "#### The Math Behind Histograms\n",
        "- The formal definition of a histogram is that it is a function, such that the *height* of bar $k$ is:\n",
        "$$\n",
        "h_k =  \\sum_{i=1}^N \\mathbb{I}\\left\\lbrace b_{k-1} < x_i \\le b_k \\right\\rbrace, \\quad k = 1, ..., B\n",
        "$$\n",
        "where $\\mathbb{I}\\{...\\}$ equals 1 when the statement inside is true, and zero otherwise.\n",
        "- When *normalized* by $N$, you can interpret this as the probability that a random draw of $X$ falls into the $k$-th bin, between $b_{k-1}$ and $b_k$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9a6c11-86d9-4d80-bd62-6d892da95769",
      "metadata": {
        "id": "ac9a6c11-86d9-4d80-bd62-6d892da95769"
      },
      "outputs": [],
      "source": [
        "# Next look at the histogram for Bond\n",
        "# Can you gather much information from this graph? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9589d4bb-c27e-4388-b7a9-37ee8245e8b4",
      "metadata": {
        "id": "9589d4bb-c27e-4388-b7a9-37ee8245e8b4"
      },
      "source": [
        "### Variables with \"Long Tails\"\n",
        "- **The bond histogram above is not very useful:** All of the data are consolidated into a single bin. This view can be unhelpful and misleading. We need some methods to deal with visualizing distributions that look like this.\n",
        "\n",
        "- **The scale leads to these strange graphs:** We often get graphs that are not meaningful to us because their values are **badly scaled**\n",
        "\n",
        "- **Computers dislike variables with bad scaling:** Stable calculations become challenging when comparing numbers of very different magnitudes.\n",
        "\n",
        "- **Log scaling:** The traditional way to smooth them is to use the *(natural) logarithm* or `log()` function. This converts multiplication/division to addition/subtraction, levels to growth rates, and shrinks large values significantly.\n",
        "\n",
        "- **Log Scaling has Drawbacks:** `np.log()` is only defined as a real number for for strictly positive numbers, so it forces us to drop zeros and negative numbers from visualizations or analysis. This is highly undesirable.\n",
        "\n",
        "- **Inverse hyperbolic sine**: An alternative method for sclaing the magnitude of a variable. `np.arcsinh()`, is defined for any number, positive or negative, and has almost the same interpretation as `np.log()`, so we often use it instead."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Log transform of the `bond` Variable"
      ],
      "metadata": {
        "id": "7jIXCAGms7BZ"
      },
      "id": "7jIXCAGms7BZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823242ca-f8f0-41e5-ad0f-ed4850605b95",
      "metadata": {
        "id": "823242ca-f8f0-41e5-ad0f-ed4850605b95"
      },
      "outputs": [],
      "source": [
        "# Let's create a new variable in the data frame\n",
        "# for the log of the bond variable\n",
        "# Try to plot the histograms. What happens?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the log is not defined for values that are 0 or below, we need to remove all values that are 0 or below from our plot."
      ],
      "metadata": {
        "id": "UtffOUjmqzdr"
      },
      "id": "UtffOUjmqzdr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate the bond value\n"
      ],
      "metadata": {
        "id": "D3yvdCyxqxb1"
      },
      "id": "D3yvdCyxqxb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now we can try the inverse hyperbolic sine transform of the `bond` variable instead"
      ],
      "metadata": {
        "id": "jeMC8LcGtAbn"
      },
      "id": "jeMC8LcGtAbn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f1e7e2-6313-4785-9d94-6bfa7e261736",
      "metadata": {
        "id": "90f1e7e2-6313-4785-9d94-6bfa7e261736"
      },
      "outputs": [],
      "source": [
        "# Calculate the argsinh of the bond variable\n",
        "# and make it a new column\n",
        "\n",
        "\n",
        "# Plot the resulting histogram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bea1d1e-6c47-4d47-8ce2-29760091dccc",
      "metadata": {
        "id": "1bea1d1e-6c47-4d47-8ce2-29760091dccc"
      },
      "source": [
        "#### Comparing the Math of the `log()` vs. `arcsinh()` functions\n",
        "\n",
        "- **Similar Derivatives:** The derivative of natural log is $1/x$, while for inverse hyperbolic sine it is $1/\\sqrt{1+x^2}$, which are so close as to render the difference negligible for our purposes\n",
        "\n",
        "- **Easy to transform between scaled and unscaled values for the data:** We won't go over it now, but it's typically easy to go back and forth between the transformed analysis and the original values in levels, so using the transformations are not a problem in analysis.\n",
        "\n",
        "- **`arcsinh()` lies slightly above `log()`:** Since `arcsinh(0)=0` but `log()` tends to be negative infinity at zero and their derivatives are similar, the `arcsinh()` curve lies above the `log()` curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "503af50a-1e0a-4fc2-9cd4-db29a102731f",
      "metadata": {
        "id": "503af50a-1e0a-4fc2-9cd4-db29a102731f"
      },
      "outputs": [],
      "source": [
        "# A visual comparison between the log and arcsinh functions\n",
        "\n",
        "# Creating the grid points to compare on\n",
        "x = np.arange(-15,15,.1)\n",
        "\n",
        "# Calculating the log and arcsinh outputs\n",
        "y1 = np.log(x)\n",
        "y2 = np.arcsinh(x)\n",
        "\n",
        "# Plotting the results\n",
        "plt.plot(x,y1, label ='Natural Log')\n",
        "plt.plot(x,y2, label='Inverse Hyperbolic Sine')\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.grid()\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Natural Log and Arcsinh')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42b9bdb-51cd-4a5e-83b0-c1e2b5fefdad",
      "metadata": {
        "id": "c42b9bdb-51cd-4a5e-83b0-c1e2b5fefdad",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Student Exercise: Histograms\n",
        "\n",
        "0. First, we need to clean the `ImposedSentenceAllChargeInContactEvent` variable. We'll rename it to be `sentence`\n",
        "\n",
        "1. Plot a histogram of the `sentence` variable. Is it badly scaled?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to clean the ImposedSentenceAllChargeInContactEvent\n",
        "\n",
        "# Isolate the column\n",
        "sentence = trial_df['ImposedSentenceAllChargeInContactEvent']\n",
        "\n",
        "# Look at unique values\n",
        "# print('Unique values of Sentence:', sentence.unique())\n",
        "\n",
        "# Replace empty strings with nans\n",
        "sentence = sentence.replace(' ', np.nan)\n",
        "\n",
        "# Update the data type to be numeric\n",
        "sentence = pd.to_numeric(sentence, errors = 'coerce')\n",
        "\n",
        "# Create a new columns for sentence with our updated data\n",
        "trial_df['sentence'] = sentence\n",
        "\n",
        "# Now look at trial_df sentence\n",
        "trial_df['sentence']"
      ],
      "metadata": {
        "id": "EbGY5-1gu-V_"
      },
      "id": "EbGY5-1gu-V_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the sentence histogram here\n"
      ],
      "metadata": {
        "id": "KWzY3wMFubz2"
      },
      "id": "KWzY3wMFubz2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use the `log()` and `arcsinh()` transformations on `sentence` and create histograms. Compare the outcomes."
      ],
      "metadata": {
        "id": "p6L3WGSOucJ-"
      },
      "id": "p6L3WGSOucJ-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the log() here\n"
      ],
      "metadata": {
        "id": "o5HySETjy6tg"
      },
      "id": "o5HySETjy6tg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the arcsinh() here\n"
      ],
      "metadata": {
        "id": "U25AdJvuy8c6"
      },
      "id": "U25AdJvuy8c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What would happen if you threw away the zeros when analyzing sentencing? How might it bias or otherwise interfere with your analysis? Hint: For additional information on the `ImposedSentenceAllChargeInContactEvent` variable, look at the codebook.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**SOLUTION:** We would overinflate the setence amount. This would make us assume everyone was sentenced and no one had a sentence of 0 months. If you created a model that predicted the sentencing time, it would always predict a larger sentence time than if the 0s were included."
      ],
      "metadata": {
        "id": "m5-w59Afucqw"
      },
      "id": "m5-w59Afucqw"
    },
    {
      "cell_type": "markdown",
      "id": "583a53d5-2131-43b9-8071-1ca06a7e39c4",
      "metadata": {
        "id": "583a53d5-2131-43b9-8071-1ca06a7e39c4",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### An Overview of Statistics (Numerical Descriptions of the Data)\n",
        "\n",
        "- **A Sample Statistic:** A function of the data. We take a list of values and aggregate it into a summary number(s) that helps us better understand the phenomenon we're interested in.\n",
        "\n",
        "- **The mean is a sample statistic**: An example sample statistic is the **mean** or **average**.To calculate the mean, We sum all of the values and divide by the total number of values. If we have $N$ observations and the values are $(x_1, x_2, ..., x_N)$, the average is\n",
        "$$\n",
        "\\bar{x} = \\dfrac{x_1+x_2+...+x_N}{N} = \\dfrac{ \\sum_{i=1}^N x_i }{N}\n",
        "$$\n",
        "The intuition is, \"Imagine you drew a number out of the hat. They're all drawn with equal probability. What kind of number do you expect to get?\"\n",
        "\n",
        "- **Statistics considers what happens to a sample statistic as $N$ grows:** The field of statistics, roughly, studies the behavior of sample statistics as the sample size $N$ gets large. For example, what is the behavior of a sample statistic as we get lots of data? Does it approach the \"true\" value, if one exists?\n",
        "\n",
        "- **EDA to Summarize** In EDA, we're typically using statistics as a way to summarize the data and understand its features, and not necessarily imputing a \"deeper meaning\" to them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ebf164-f049-4251-b9f9-b51d0b0c9e34",
      "metadata": {
        "id": "c3ebf164-f049-4251-b9f9-b51d0b0c9e34",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Always, always, always, look at your data\n",
        "![Lawyer Salaries](https://github.com/DS3001/EDA/blob/main/lawyerSalaries2018.jpg?raw=1)\n",
        "- How *useful* is it to say, \"The average yearly salary of a lawyer is about $100k?\"\n",
        "- Statistics can be incredibly misleading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df2ee83d-2c2e-4a41-b572-f2bcfc260579",
      "metadata": {
        "id": "df2ee83d-2c2e-4a41-b572-f2bcfc260579"
      },
      "source": [
        "### Statistics: Measures of Central Tendency\n",
        "- These statistics correspond to values around which the data are concentrated:\n",
        "    - **Mode**: The most frequently occuring value in the data. Calculated using the following code: `df[var].mode()`\n",
        "    - **Median**: The value(s) at which half the population is above and half the population is below. Calculated using the following code: `df[var].median()`\n",
        "    - **Mean**: The numeric average value of the data. Calculated using the following code: `df[var].mean()`.\n",
        "$$\n",
        "\\bar{x} = \\dfrac{x_1+x_2+...+x_N}{N} = \\dfrac{ \\sum_{i=1}^N x_i }{N}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3020f484-1367-4f35-92f5-1dfb0c3be8fa",
      "metadata": {
        "id": "3020f484-1367-4f35-92f5-1dfb0c3be8fa"
      },
      "outputs": [],
      "source": [
        "# Look at the histogram for the GiniIndex\n",
        "# Calculate the mean, median, and mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c7c29b-ca36-4435-ba2d-354f6babbb92",
      "metadata": {
        "id": "83c7c29b-ca36-4435-ba2d-354f6babbb92"
      },
      "outputs": [],
      "source": [
        "# Look at the histogram for the bond_arcsinh variable\n",
        "# Calculate the mean, median, and mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17d3c19-99bd-40d4-8da7-66f4c25a5e74",
      "metadata": {
        "id": "e17d3c19-99bd-40d4-8da7-66f4c25a5e74"
      },
      "source": [
        "### Statistics: Measures of Rank\n",
        "\n",
        "- **Ordering data by magnitude:** Consider lining the data up by magnitude, from smallest to largest (ascending order).\n",
        "\n",
        "- Two ways to look at the data in terms of rank:\n",
        "  - **Percentiles:** The **p-th percentile** is the value for which $p\\%$ of the population is below $p$'s value and $(1-p)\\%$ of the population is above $p$'s value. Ex. If the value 10 is the 70th percentile in a data set, it means that 70% of data points are below 10.\n",
        "  - **Quantiles:** If you use decimals instead of percents, like $.05$ for $5\\%$ or $.50$ for $50\\%$, the word **quantile** is typically used. Ex. If the value 10 is the 0.7 quantile, that means that 70% of the data points are below 10. Calculated in Pandas using: `df[var].quantile(p)`\n",
        "\n",
        "- **Quantiles and the median are robust to outliers:** Moving extremely large or small values won't affect the median or significantly change the rankings."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identifying the Quantiles"
      ],
      "metadata": {
        "id": "YNFeqURMbhUU"
      },
      "id": "YNFeqURMbhUU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b882e6ab-0566-4443-a6a1-5ff63c4719fb",
      "metadata": {
        "id": "b882e6ab-0566-4443-a6a1-5ff63c4719fb"
      },
      "outputs": [],
      "source": [
        "# Look at the quantiles of the GiniIndex varaible\n",
        "var = 'GiniIndex'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Empirical Cumulative Distribution Function (ECDF):** The ECDF plots the variable of interest on the x-axis and the quantile on the y-axis.\n",
        "\n",
        "You can get the quantiles for each value using the following code: `df[var].rank(method = 'average', pct = True)`. Then you plot your data on the x-axis and the quantiles you calculated using `rank` on the y-axis to create the ECDF."
      ],
      "metadata": {
        "id": "WP2WOgDncAmn"
      },
      "id": "WP2WOgDncAmn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the ECDF for the GiniIndex variable\n"
      ],
      "metadata": {
        "id": "hq6ZLN07cbw7"
      },
      "id": "hq6ZLN07cbw7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ff9850-160a-45c2-b463-ac06c63378b3",
      "metadata": {
        "id": "c0ff9850-160a-45c2-b463-ac06c63378b3"
      },
      "outputs": [],
      "source": [
        "# Repeat the same steps of identifying the quantiles and\n",
        "# ECDF for the 'bond' variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d318c63-56a8-4b22-b4af-48b97008f2e2",
      "metadata": {
        "id": "5d318c63-56a8-4b22-b4af-48b97008f2e2",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "###  Statistics: Measures of Dispersion\n",
        "- Measures of dispersion describe how \"spread out\" the data are:\n",
        "    - **Range:** The minimum and maximum values of the data.\n",
        "    - **Interquartile Range:** The distance between the 0.25-quantile and 0.75-quantile, which includes the middle half of the data\n",
        "    - **Variance:** The average squared distance from the mean,\n",
        "$$\n",
        "s^2 = \\dfrac{(x_1-\\bar{x})^2 + (x_2 + \\bar{x})^2 + ... + (x_N - \\bar{x})^2}{N-1} = \\dfrac{\\sum_{i=1}^N (x_i-\\bar{x})^2 }{N-1}\n",
        "$$\n",
        "So take the value of each observation $i$, subtract off the mean $\\bar{x}$, square that, and then divide by $N-1$. If the data are all clustered around $\\bar{x}$, this will be small, but if the data are very spread out, this will be larger.\n",
        "    - **Standard Deviation:** The square root of the variance,\n",
        "$$\n",
        "s = \\sqrt{s^2} = \\sqrt{ \\dfrac{\\sum_{i=1}^N (x_i-\\bar{x})^2 }{N-1} }\n",
        "$$\n",
        "- Why deal with the standard deviation instead of variance? The standard deviation is in the same units as the original variable, but the variance is approximately an average. They end up having have different statistical properties in small samples. Some models are more naturally parameterized in terms of the variance rather than the standard deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison of two different distributions with the same mean but different dispersion\n",
        "\n",
        "For your own test, try to move the values of `std1` and `std2` to see what happens as you increase the standard deviation. Also try changing `n` to see what happens to how sample statistics change as the number of samples change."
      ],
      "metadata": {
        "id": "3GpumwhPExjh"
      },
      "id": "3GpumwhPExjh"
    },
    {
      "cell_type": "code",
      "source": [
        "### Parameters to change\n",
        "n = 10000 # Number of points to draw\n",
        "mean = 0 # Mean for both distribtuions\n",
        "std1 = 1 # Standard deviation for first distiribution\n",
        "std2 = 3 # Standard deviation for second distribution\n",
        "nbins = 50\n",
        "###\n",
        "\n",
        "# Randomly draw points from normal distribution\n",
        "x1 = np.random.normal(loc = mean, scale = std1, size = n)\n",
        "x2 = np.random.normal(loc = mean, scale = std2, size = n)\n",
        "\n",
        "# Print a Comparison of the range, IQR, sample standard varaince, and sample\n",
        "# standard deviation\n",
        "print(\n",
        "f'''\n",
        "Distribution 1:\n",
        "\\tRange: {max(x1)-min(x1)}\n",
        "\\tIQR: {np.quantile(x1,.75)-np.quantile(x1,.25)}\n",
        "\\tIQR End Points: [{np.quantile(x1,.25)},  {np.quantile(x1,.75)}]\n",
        "\\tSample Variance: {np.var(x1)}\n",
        "\\tSample STD: {np.std(x1)}\n",
        "'''\n",
        ")\n",
        "\n",
        "print(\n",
        "f'''\n",
        "Distribution 1:\n",
        "\\tRange: {max(x2)-min(x2)}\n",
        "\\tIQR: {np.quantile(x2,.75)-np.quantile(x2,.25)}\n",
        "\\tIQR End Points: [{np.quantile(x2,.25)},  {np.quantile(x2,.75)}]\n",
        "\\tSample Variance: {np.var(x2)}\n",
        "\\tSample STD: {np.std(x2)}\n",
        "'''\n",
        ")\n",
        "\n",
        "# Histogram of both distributions for comparison\n",
        "plt.hist(x1, label = 'Distribution 1', color = 'firebrick', alpha = 0.2, bins = nbins)\n",
        "plt.hist(x2, label = 'Distribution 2', color = 'dodgerblue', alpha = 0.2, bins = nbins)\n",
        "plt.xlabel('Value of X')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(f'Comparison of Distributions with Different Dispersion')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ernOtwhJeMr6"
      },
      "id": "ernOtwhJeMr6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4e1ba175-92a1-4221-9d72-237c744f7124",
      "metadata": {
        "id": "4e1ba175-92a1-4221-9d72-237c744f7124"
      },
      "source": [
        "### Boxplots\n",
        "\n",
        "- **Move towards visualizing dispersion:** The rank and dispersion information is useful to illustrate in a plot, since it can feel somewhat abstract when just looking at the numbers compared to a histogram.\n",
        "\n",
        "- **Boxplot**: A graph to visualize the 5-number summary:\n",
        "    - **Median:** The middle bar (green in the below plot) is the median/0.5-quantile/50%-percentile\n",
        "\n",
        "    - **IQR:** The \"box\" represents the interquartile range (IQR): The range of values containing everything from the 0.25-quantile to the 0.75-quantile\n",
        "\n",
        "    - **Whiskers:** The \"whiskers\" include a range of values from the first quartile minus $\\frac{3}{2} * \\text{IQR}$ to the third quartile plus $\\frac{3}{2} * \\text{IQR}$\n",
        "\n",
        "    - **Outliers:** Values outside the whiskers are typically considered **outliers**. They are represented as points outside the whiskers.\n",
        "\n",
        "- This plot is intended to illustrate the rank information in a useful way\n",
        "\n",
        "$\\text{Boxplot of GiniIndex}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f850c91a-7b51-46d6-8103-ab9000474a24",
      "metadata": {
        "id": "f850c91a-7b51-46d6-8103-ab9000474a24"
      },
      "outputs": [],
      "source": [
        "# Create a box plot of the GiniIndex variable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boxplot for GiniIndex but this time in the horizontal orientation\n"
      ],
      "metadata": {
        "id": "FJLb7PIyi2aW"
      },
      "id": "FJLb7PIyi2aW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741acb25-4ac5-4359-b5e4-76264cff256d",
      "metadata": {
        "id": "741acb25-4ac5-4359-b5e4-76264cff256d"
      },
      "outputs": [],
      "source": [
        "# Create a box plot for the bond variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd048426-08ab-4775-a915-93e49e8cc280",
      "metadata": {
        "id": "cd048426-08ab-4775-a915-93e49e8cc280"
      },
      "outputs": [],
      "source": [
        "# Look at the bond variable that we transformed using arcsinh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a2d7f32-1251-4b30-86b8-785ac4eb4114",
      "metadata": {
        "id": "1a2d7f32-1251-4b30-86b8-785ac4eb4114"
      },
      "source": [
        "### Variable Descriptions\n",
        "\n",
        "- Many stats packages report a **five-number+** summary:\n",
        "  - Five-number summary:\n",
        "    1. Minimum\n",
        "    2. 25% Percentile\n",
        "    3. Median\n",
        "    4. 75% percentile\n",
        "    5. Maximum\n",
        "  - The plus:\n",
        "    6. Mean\n",
        "    7. Standard deviation\n",
        "    8. Count: How many non-missing observations are recorded\n",
        "\n",
        "- In Pandas, you can get the 5-number summary with `df[var].describe()`\n",
        "\n",
        "- From `.describe()`, you can quickly compute almost all the statistics we've mentioned\n",
        "\n",
        "- The `count` value is the number of non-missing entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7eb54b9-7415-4790-a13b-d369e8145fec",
      "metadata": {
        "id": "c7eb54b9-7415-4790-a13b-d369e8145fec"
      },
      "outputs": [],
      "source": [
        "# Get the description of the age variable\n",
        "# Compute the variance and IQR using the description\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36735fd3-d741-4d3c-988c-289a6a5ff7d7",
      "metadata": {
        "id": "36735fd3-d741-4d3c-988c-289a6a5ff7d7"
      },
      "source": [
        "### What do you do with outliers?\n",
        "\n",
        "- Maybe nothing: They're part of the data. Maybe you trim the outliers and drop them, or **windsorize** and replace them with a high or low value.\n",
        "\n",
        "- The outliers will typically exert *leverage* on the analysis: extreme values will influence the outcomes of your estimates or algorithm (e.g. they disproportionately affect the variance)\n",
        "\n",
        "- But if the outliers are \"really part of the data,\" that leverage can be totally legitimate\n",
        "\n",
        "- What you want to be certain of is that the outliers are actually representative of the population of interest --- some observations might have characteristics that make them uncharacteristic of the data you expect to see in the future, and your models will be less useful if they are trained on those data\n",
        "\n",
        "- The field of *robust statistics* is generally concerned with estimating models when the presence of outliers is likely to interfere with the results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad1c0677-b4ea-49ae-8be5-0245be290d96",
      "metadata": {
        "id": "ad1c0677-b4ea-49ae-8be5-0245be290d96"
      },
      "source": [
        "## Student Exercise: Statistics and Boxplots\n",
        "\n",
        "1. Generate a description of the `sentence` variable. What is the sample mean and sample standard deviation?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "U-WEg1vAoCq2"
      },
      "id": "U-WEg1vAoCq2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the median, and mode of the `sentence` variable? What is the variance? The IQR?"
      ],
      "metadata": {
        "id": "u78kbeIUoE5e"
      },
      "id": "u78kbeIUoE5e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "m3CdW8k5oEJR"
      },
      "id": "m3CdW8k5oEJR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Make a boxplot. Are there a lot of outliers? Explain."
      ],
      "metadata": {
        "id": "HKH6FFluoGtE"
      },
      "id": "HKH6FFluoGtE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "DRAwfFUyoG2Y"
      },
      "id": "DRAwfFUyoG2Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Create an `outlier` dummy for the bond variable that indicates an observation is more than $1.5 \\times IQR$ away from the $IQR$. (There are many ways to do this, some easier than others.). What proportion of the observations are outliers?"
      ],
      "metadata": {
        "id": "_mm-iAGioHEU"
      },
      "id": "_mm-iAGioHEU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "K_p7II1eoO5f"
      },
      "id": "K_p7II1eoO5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f6ae3ae8-8294-4cc1-99f9-d7e0c84e2624",
      "metadata": {
        "id": "f6ae3ae8-8294-4cc1-99f9-d7e0c84e2624"
      },
      "source": [
        "### Scatter Plots (Two Variables, Numeric)\n",
        "\n",
        "- **Scatter Plots to view relationship between two numeric variables:** Just like cross-tabs allow you to think about two variables at once, scatter plots provide a way of looking at the association between two variables in the data set\n",
        "\n",
        "- **What's a scatterplot?** Pick two variables, $x$ and $y$. For each pair of values $(x_i, y_i)$ for observation $i$, you make a dot. Plot all the dots for all observations, $i=1,...,N$.\n",
        "\n",
        "- **Goal of the scatter plot:** To uncover patterns of association between the two variables being plotted."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quickly clean the prior felonies and misdemenors variables\n",
        "\n",
        "# Set up prior felonies variable\n",
        "prior_F = trial_df['PriorConvs_Fel']\n",
        "prior_F = prior_F.replace(' ', np.nan)\n",
        "prior_F = pd.to_numeric(prior_F, errors = 'coerce')\n",
        "trial_df['prior_F'] = prior_F\n",
        "\n",
        "# Set up prior misdemenors variable\n",
        "prior_M = trial_df['PriorConvs_Misd']\n",
        "prior_M = prior_M.replace(' ', np.nan)\n",
        "prior_M = pd.to_numeric(prior_M, errors = 'coerce')\n",
        "trial_df['prior_M'] = prior_M"
      ],
      "metadata": {
        "id": "ViG4UFri2PMu"
      },
      "id": "ViG4UFri2PMu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ba646a-924e-4e81-b6e5-f0cd4862587d",
      "metadata": {
        "id": "71ba646a-924e-4e81-b6e5-f0cd4862587d"
      },
      "outputs": [],
      "source": [
        "# Plot a scatter plot of the bond and age\n",
        "# Plot a scatter plot of the GiniIndex and Age\n",
        "# Plot a scatter plot of the bond arcsinh and age\n",
        "# Plot a scatter plot of prior misdemenors (prior_M) and felonies (prior_F)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0655ba17-ebdc-48ba-a8a7-5e29c57cfdac",
      "metadata": {
        "id": "0655ba17-ebdc-48ba-a8a7-5e29c57cfdac"
      },
      "source": [
        "### Statistics: Measures of Association\n",
        "\n",
        "- **Covariance:** Essentially, the common variance between two variables. Looking at how often the two variables are going in the same direction with one another.\n",
        "$$\n",
        "\\text{cov}(x,y) = \\dfrac{(x_1-\\bar{x})(y_1-\\bar{y}) + (x_2-\\bar{x})(y_2-\\bar{y})+...+(x_N-\\bar{x})(y_N-\\bar{y}) }{N-1} = \\dfrac{\\sum_{i=1}^{N} (x_i-\\bar{x})(y_i-\\bar{y}) }{N-1}\n",
        "$$\n",
        "*Notice how $\\text{cov}(x,x) = s^2$.*\n",
        "\n",
        "- **Comaprison between pairs of points:** Look at each pair $x_i$ and $y_i$. If they tend to both be above or below their averages, then there is positive covariance. If one tends to be above its average when the other is below, then there is negative covariance.\n",
        "\n",
        "- **Correlation:** The covariance normalized by the\n",
        "$$\n",
        "r_{x,y} = \\dfrac{\\text{cov}(x,y)}{ s_x s_y}\n",
        "$$\n",
        "This is helpful because it is between -1 and 1, with 1 being perfect positive correlation, -1 being perfect negative correlation, and 0 being no correlation at all. *Important Note:* Correlation will only capture linear relationships between variables, not non-linear."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820063cc-cdc9-43e8-b23f-55769bc88799",
      "metadata": {
        "id": "820063cc-cdc9-43e8-b23f-55769bc88799"
      },
      "source": [
        "#### Covariance and Correlation Matrices\n",
        "\n",
        "- **Calculating covariance and correlation with Pandas:** The function `df.cov()` will compute all of the variances and covariances for everything in your dataframe, and `df.corr()` will compute the correlations.\n",
        "\n",
        "- **Ouputs of `df.cov()` and `df.corr()`:** The output will be a matrix. The variances of the variables will be on the diagonal, and the covariances/correlations will be the off-diagonal terms\n",
        "\n",
        "- **Restricting number of outputs:** You probably want to use `df.loc[:,list]` to restrict attention to a set of variables in `list`, rather than compute all the possible covariances/correlations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5114b267-abf8-416a-91d7-306785d68750",
      "metadata": {
        "id": "5114b267-abf8-416a-91d7-306785d68750"
      },
      "outputs": [],
      "source": [
        "# Calculate the covariance and correlation matrices of age, bond, and GiniIndex\n",
        "# Define the variables to consider\n",
        "vars = ['age', 'bond', 'GiniIndex']\n",
        "\n",
        "# Compute the covariance and correlations of the variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5c4112-d7f0-4f6c-84c2-7c6b466eb9a4",
      "metadata": {
        "id": "ff5c4112-d7f0-4f6c-84c2-7c6b466eb9a4"
      },
      "source": [
        "## Student Exercise: Scatter Plots and Covariance\n",
        "\n",
        "1. Plot a scatterplot of the `sentence` and `bond` variables. What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "xO3nDyjvuwRu"
      },
      "id": "xO3nDyjvuwRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Try a scatterplot of the inverse hyperbolic sine of `sentence` and `bond`."
      ],
      "metadata": {
        "id": "q8qvkG4Uuwf1"
      },
      "id": "q8qvkG4Uuwf1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "CLdSYyZfuwo3"
      },
      "id": "CLdSYyZfuwo3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What are the covariance and correlation matrices between `sentence` and `bond`?"
      ],
      "metadata": {
        "id": "GG6UvAQiuw82"
      },
      "id": "GG6UvAQiuw82"
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here\n"
      ],
      "metadata": {
        "id": "wSoCSeVduxMd"
      },
      "id": "wSoCSeVduxMd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "88c19d16-1d21-47b9-94e6-eec6b31c3138",
      "metadata": {
        "id": "88c19d16-1d21-47b9-94e6-eec6b31c3138"
      },
      "source": [
        "### Grouping\n",
        "\n",
        "- **Conditional Grouping:** We often want to **condition** or **group** our sample statistics and plots on specific categorical variables.\n",
        "  - For example, the bond or sentence conditional on race or sex. This provides valuable context for what the numbers mean.\n",
        "\n",
        "- **Diffentiating between categorical cases:** A lot of our tools immediately become more powerful when we can quantitatively differentiate between different categorical cases.\n",
        "\n",
        "- We'll demonstrate grouping using Kernel Density Plots, Pivot Tabels, and Box Plots."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aea1e0f-26c6-4edc-88fd-d41065678c2c",
      "metadata": {
        "id": "3aea1e0f-26c6-4edc-88fd-d41065678c2c"
      },
      "source": [
        "### Kernel Density Plots\n",
        "\n",
        "- **Downside of histograms:** Plotting multiple variables on the same histogram at the same time often becomes a jumbled mess since they are filled in. Is the solution to stack them? Jitter them?\n",
        "\n",
        "- **Enter Kernel Density Plots:** The alternative is to use a smoothed line to represent each variable; this is called a **kernel density plot**.\n",
        "\n",
        "- **How Kernel Desnity Plots are Created:** The intuition of a kernel density plot is that each data point gets its own little bell curve (normal distribution), centered at its value. All the bell curves are averaged together.\n",
        "  - So if data are bunched closely, their bell curves sum to a large value. If the data are sparse around some values, the sum is small\n",
        "  - This smooths the jaggedness of histograms.\n",
        "\n",
        "- **Plotting a desnity plot in Pandas:** You can plot a kernel density plot of your data using the following code: `df[var].plot.density()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae41284a-a954-404d-98a7-3ceb143f3c69",
      "metadata": {
        "id": "ae41284a-a954-404d-98a7-3ceb143f3c69"
      },
      "outputs": [],
      "source": [
        "# Create a kernel density plot of the age variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67b188b-4f0f-48bb-8b91-61ba93287eb7",
      "metadata": {
        "id": "e67b188b-4f0f-48bb-8b91-61ba93287eb7"
      },
      "outputs": [],
      "source": [
        "# Compare this to the histogram for age\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6618d9-2764-4b1c-8872-6c05f53e6421",
      "metadata": {
        "id": "8b6618d9-2764-4b1c-8872-6c05f53e6421"
      },
      "source": [
        "#### Upside and Downside of Kernel Density Plots\n",
        "\n",
        "- **Upside:** It's easy to visualize many density plots at once, grouped by a categorical variable, and the choice of \"bins\" isn't as arbitrary (there are a lot of good ways to pick the **bandwidth**)\n",
        "\n",
        "- **Downside:** If the data have big spikes, the kernel density plot struggles to represent that faithfully, because it is trying to smooth everything out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1b7b24-1eea-49f4-a7a1-fb401ea34f5c",
      "metadata": {
        "id": "5d1b7b24-1eea-49f4-a7a1-fb401ea34f5c"
      },
      "outputs": [],
      "source": [
        "# Plot the kernel density plot for bond\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with the histogram\n"
      ],
      "metadata": {
        "id": "aU0xHDsmLvM4"
      },
      "id": "aU0xHDsmLvM4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9adfa2-ad17-4cb6-abd7-dbe50c94a1f6",
      "metadata": {
        "id": "da9adfa2-ad17-4cb6-abd7-dbe50c94a1f6"
      },
      "outputs": [],
      "source": [
        "# What about for the bond_arcsinh variable?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with the histogram as well\n"
      ],
      "metadata": {
        "id": "uqt3R2IXMArm"
      },
      "id": "uqt3R2IXMArm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f9ac7173-3e47-4a06-8f25-9bf704f1538d",
      "metadata": {
        "id": "f9ac7173-3e47-4a06-8f25-9bf704f1538d"
      },
      "source": [
        "### Conditioning on a Categorical Variable: Pivot Tables and Grouped Density Plots\n",
        "\n",
        "- To make very useful plots to compare the same variable for different groups, you have to do two steps:\n",
        "    1. Make a **pivot table** of the values, using `df_wide = df.pivot(columns=group,values=var)` where `group_by` is the categorical variable to condition on, and `var` is the variable to plot. This is often called a \"wide\" dataframe because it explodes values by columns.\n",
        "    2. Call the `.plot.density()` method on the `df_wide` dataframe you built in step 1\n",
        "\n",
        "- The result is a kernel density plot, where each line corresponds to one of the values that the conditioning categorical variable takes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37576cf6-65a6-4e4e-a479-53322b3d88b4",
      "metadata": {
        "id": "37576cf6-65a6-4e4e-a479-53322b3d88b4"
      },
      "outputs": [],
      "source": [
        "# Look at the GiniIndex variable density plot\n",
        "# grouped by the race variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f01514-86de-4012-8e87-18f3f049122e",
      "metadata": {
        "id": "d5f01514-86de-4012-8e87-18f3f049122e"
      },
      "outputs": [],
      "source": [
        "# Next look at the bond arcsinh variable\n",
        "# grouped by the case_type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed25b55a-9203-4a33-a199-a7066bc1b353",
      "metadata": {
        "id": "ed25b55a-9203-4a33-a199-a7066bc1b353"
      },
      "outputs": [],
      "source": [
        "# Arcsinh transform the prior_F and prior_M variables\n",
        "# Plot their density plots grouped by sex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7ad606-aa42-45f7-be37-ac8543d1e7c3",
      "metadata": {
        "id": "2c7ad606-aa42-45f7-be37-ac8543d1e7c3"
      },
      "source": [
        "### Grouped Boxplots\n",
        "- Grouping for boxplots is even easier: `df.boxplot(column = var, by = group_by)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dcaff1-4efe-4df9-8c21-2530610e09a2",
      "metadata": {
        "id": "f6dcaff1-4efe-4df9-8c21-2530610e09a2"
      },
      "outputs": [],
      "source": [
        "# Create boxplots of the Gini Index grouped by sex and race\n",
        "# Create boxplots looking at Bond and Arcsinh Bond grouped by race\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca9cd99-b61a-4210-a5de-8eba59e5549e",
      "metadata": {
        "id": "4ca9cd99-b61a-4210-a5de-8eba59e5549e"
      },
      "source": [
        "### Grouped Descriptions\n",
        "\n",
        "- We can group our calculations like `.describe()` in a similar way:\n",
        "    1. Use `df.loc[:,[group,var]]` to get the subset of the dataframe you want to analyze.\n",
        "\n",
        "    2. Then `.groupby(group).describe()` to apply `.describe()` to `var` for each `group`\n",
        "    \n",
        "- Like the grouped kernel densities, this can be a really useful way of adding context to numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f8744a5-9fa0-41ca-b54d-00a38c8ad04b",
      "metadata": {
        "id": "2f8744a5-9fa0-41ca-b54d-00a38c8ad04b"
      },
      "outputs": [],
      "source": [
        "# Describe the bond variable, grouped by case type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78d4e36-86d5-465b-a706-ec220c41048f",
      "metadata": {
        "id": "b78d4e36-86d5-465b-a706-ec220c41048f"
      },
      "outputs": [],
      "source": [
        "# Do the same for bond by is_poor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4661f1b9-ab04-4368-80cb-9b62ac02aaba",
      "metadata": {
        "id": "4661f1b9-ab04-4368-80cb-9b62ac02aaba"
      },
      "outputs": [],
      "source": [
        "# Look at the variables is_poor, case_type, and bond\n",
        "# Group by is_poor and case_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46a89719-5789-4b13-a7d9-9e050442b12e",
      "metadata": {
        "id": "46a89719-5789-4b13-a7d9-9e050442b12e"
      },
      "source": [
        "## Student Exercise: Grouping\n",
        "\n",
        "- For the `sentence` and `sentence_arcsinh` variables, create grouped kernel density, boxplot, and descriptive statistics for a categorical variable in the data (e.g. `case_type`, `sex`, `race`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here for sentence\n"
      ],
      "metadata": {
        "id": "7yYDf3Le6yYV"
      },
      "id": "7yYDf3Le6yYV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Here for sentence_arcsinh\n"
      ],
      "metadata": {
        "id": "mXCb2lGt7F1z"
      },
      "id": "mXCb2lGt7F1z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6e7fd5ac-c017-48ed-908d-6f6b034aad5a",
      "metadata": {
        "id": "6e7fd5ac-c017-48ed-908d-6f6b034aad5a"
      },
      "source": [
        "## Conclusion\n",
        "- These graphs are not very aesthetically pleasing -- you wouldn't put them in a publication or on your web page, probably\n",
        "- But they are very quick to make, and it all happens inside Pandas, instead of moving on to other packages\n",
        "- You'll find that if you want pretty plots, you need a complex Application Programming Interface (API), and the more complex the API, the more specialized the skills become\n",
        "- MatPlotLib and Seaborn provide very nice plots (and ggplot2), but ask you to train your mind to think more specifically on their terms"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}